{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "77ae358d-9f80-4af1-9528-e6a33a568505",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "import numpy as np\n",
    "import copy\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.preprocessing import LabelEncoder, OneHotEncoder\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.metrics import precision_score, recall_score, f1_score\n",
    "from sklearn.metrics import confusion_matrix, ConfusionMatrixDisplay\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib.colors import LogNorm\n",
    "from datetime import datetime\n",
    "import math as m"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "62b2e2f7-bd66-4e2d-b5e2-adec8baa12f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device(\"cuda\") if torch.cuda.is_available() else torch.device(\"cpu\")"
   ]
  },
  {
   "cell_type": "raw",
   "id": "eb77b9a7-aa6a-4303-a105-3e147bccd4b7",
   "metadata": {},
   "source": [
    "torch.version.cuda\n",
    "torch.cuda.empty_cache()"
   ]
  },
  {
   "cell_type": "raw",
   "id": "5574024f-00fc-42b9-a6d9-de83ad7d14b9",
   "metadata": {},
   "source": [
    "torch.cuda.get_device_name(torch.cuda.current_device())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "a8eabc73-eabc-43b9-b64b-6c511bf0a9ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Carregar dados\n",
    "with open('df_pedidos_baixados_2020_a_2023_processado.pkl', 'rb') as file:\n",
    "    dados = pickle.load(file)\n",
    "dados = dados[dados.Ano>=2021]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "2d4753d8-855f-43d6-a7a5-ffa3ffa9a32b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(146082, 8)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dados.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "0b64ced0-6c5b-44a1-b007-ebee1c7c9384",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(178,)\n",
      "(139027, 4)\n",
      "(137,)\n"
     ]
    }
   ],
   "source": [
    "percentual_de_recorte = 95  # Ajustar aqui para recortar\n",
    "#oportunidade de melhoria: nao descartar esses dados, usar para amostrar os \"outros\"\n",
    "recorte_amostral = dados.query(f'PercentualAcumulado_2020_2023 <= {percentual_de_recorte}')\\\n",
    "                        .sort_values(by=['PercentualAcumulado_2020_2023']).copy()\n",
    "print(recorte_amostral.OrgaoDestinatario.unique().shape)\n",
    "\n",
    "percentual_limite = 90 # Ajustar aqui para definir os \"Outros\" (percentual_de_recorte-percentual_limite)\n",
    "recorte_amostral['Orgao_alvo'] = recorte_amostral.apply(lambda row: row['OrgaoDestinatario'] \n",
    "                               if row['PercentualAcumulado_2020_2023'] <= percentual_limite else 'Outros', axis=1)\n",
    "recorte_amostral = recorte_amostral[['Orgao_alvo', 'Mês', 'Dia da Semana', 'DetalhamentoSolicitacao']]\n",
    "print(recorte_amostral.shape)\n",
    "print(recorte_amostral.Orgao_alvo.unique().shape) # qtd de classes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "c404dc57-0e08-4376-9d32-534e4f26ab3f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(139027, 13845)\n"
     ]
    }
   ],
   "source": [
    "# Vetorização TF-IDF\n",
    "max_features_tfidf=14000\n",
    "max_df=0.1\n",
    "min_df=0.0001\n",
    "ngram_range=(1,1)\n",
    "vectorizer = TfidfVectorizer(max_features=max_features_tfidf, max_df=max_df, min_df=min_df, ngram_range=ngram_range)\n",
    "X_tfidf = vectorizer.fit_transform(recorte_amostral['DetalhamentoSolicitacao'])\n",
    "\n",
    "# Codificação dos rótulos\n",
    "label_encoder = LabelEncoder()\n",
    "y_encoded = label_encoder.fit_transform(recorte_amostral['Orgao_alvo'])\n",
    "\n",
    "y_encoded = torch.tensor(y_encoded, dtype=torch.long)\n",
    "y_encoded = nn.functional.one_hot(y_encoded) \n",
    "\n",
    "# Codificação dos parâmetros adicionais: mês e dia da semana\n",
    "onehot_encoder = OneHotEncoder()\n",
    "mes_dia_semana_encoded = onehot_encoder.fit_transform(recorte_amostral[['Mês', 'Dia da Semana']])\n",
    "print(X_tfidf.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "21808f8c-9981-4eb5-acc4-07d7285b2398",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Definindo conjunto de dados personalizado para PyTorch\n",
    "class CustomDataset(Dataset):\n",
    "    def __init__(self, X_tfidf, mes_dia_semana, y):\n",
    "        self.X_tfidf = X_tfidf\n",
    "        self.mes_dia_semana = mes_dia_semana\n",
    "        self.y = y\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.X_tfidf)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        return self.X_tfidf[idx], self.mes_dia_semana[idx], self.y[idx]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "321062ee-86a9-46ba-a8fa-b49c1c36f07e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Divisão em conjunto de treinamento e teste\n",
    "X_train_tfidf, X_test_tfidf, y_train, y_test, mes_dia_semana_train, mes_dia_semana_test = train_test_split(\n",
    "    X_tfidf, y_encoded, mes_dia_semana_encoded, test_size=0.99, random_state=42, stratify=y_encoded)\n",
    "\n",
    "# Convertendo os dados para tensores densos\n",
    "X_train_tfidf_tensor = torch.tensor(X_train_tfidf.toarray(), dtype=torch.float32) \n",
    "X_test_tfidf_tensor = torch.tensor(X_test_tfidf.toarray(), dtype=torch.float32) \n",
    "mes_dia_semana_train_tensor = torch.tensor(mes_dia_semana_train.toarray(), dtype=torch.float32) \n",
    "mes_dia_semana_test_tensor = torch.tensor(mes_dia_semana_test.toarray(), dtype=torch.float32) \n",
    "y_train_tensor = y_train \n",
    "y_test_tensor = y_test \n",
    "\n",
    "# Criando DataLoader para conjuntos de treinamento e teste\n",
    "train_dataset = CustomDataset(X_train_tfidf_tensor, mes_dia_semana_train_tensor, y_train_tensor)\n",
    "train_loader = DataLoader(train_dataset, batch_size=64, shuffle=True)\n",
    "\n",
    "test_dataset = CustomDataset(X_test_tfidf_tensor, mes_dia_semana_test_tensor, y_test_tensor)\n",
    "test_loader = DataLoader(test_dataset, batch_size=64, shuffle=False)"
   ]
  },
  {
   "cell_type": "raw",
   "id": "0f34fb64-3115-4d5a-8281-172f018b5f42",
   "metadata": {},
   "source": [
    "# Definindo o modelo de rede neural ## opcoes: 13 e 5, 14 e 6, 21 e 9, 28 e 12 ## sem dropout, sem early stop\n",
    "camada1 = 60\n",
    "camada2 = 30\n",
    "class NeuralNetwork(nn.Module):\n",
    "    def __init__(self, input_tfidf_shape, input_mes_dia_semana_shape, output_shape, dropout_rate=0.9): \n",
    "        super(NeuralNetwork, self).__init__()\n",
    "        tamanho_entrada = input_tfidf_shape + input_mes_dia_semana_shape\n",
    "        torch.manual_seed(42)\n",
    "        self.fc1 = nn.Linear(tamanho_entrada, camada1)  \n",
    "        self.fc2 = nn.Linear(camada1, camada2)\n",
    "        self.fc3 = nn.Linear(camada2, output_shape)\n",
    "        self.relu = nn.ReLU()\n",
    "        self.dropout = nn.Dropout(p=dropout_rate)\n",
    "        self.logsoftmax = nn.LogSoftmax(dim=1)\n",
    "\n",
    "    def forward(self, x_tfidf, x_mes_dia_semana):\n",
    "        x = torch.cat((x_tfidf, x_mes_dia_semana), dim=1)\n",
    "        #x = self.relu(self.fc1(x))\n",
    "        x = self.dropout(self.relu(self.fc1(x)))\n",
    "        x = self.dropout(self.relu(self.fc2(x)))\n",
    "        #x = self.relu(self.fc2(x))\n",
    "        x = self.logsoftmax(self.fc3(x))\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f9a8e3d6-b4e2-434a-ad55-3340324dd609",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Inicializando o modelo\n",
    "input_tfidf_shape = X_train_tfidf.shape[1]\n",
    "input_mes_dia_semana_shape = mes_dia_semana_train.shape[1]\n",
    "output_shape = y_encoded.shape[1]\n",
    "#model = NeuralNetwork(input_tfidf_shape, input_mes_dia_semana_shape, output_shape).to(device) #####"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a74d19b0-a147-41e0-97ab-ca416f61b838",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Função para avaliação do modelo\n",
    "def evaluate_model(model, test_loader, criterion):\n",
    "    model.eval()\n",
    "    correct = 0\n",
    "    total = 0\n",
    "    y_pred = []\n",
    "    y_true = []\n",
    "    total_loss = 0\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        \n",
    "        for data in test_loader:\n",
    "            \n",
    "            inputs_tfidf, inputs_mes_dia_semana, labels = data\n",
    "            inputs_tfidf = inputs_tfidf.to(device) #####             #####\n",
    "            inputs_mes_dia_semana = inputs_mes_dia_semana.to(device) #####\n",
    "            labels = labels.to(device) #####                         #####\n",
    "            \n",
    "            outputs = model(inputs_tfidf.float(), inputs_mes_dia_semana.float())\n",
    "            _, predicted = torch.max(outputs.data, 1)\n",
    "            total += labels.size(0)\n",
    "            correct += (predicted == torch.max(labels, 1)[1]).sum().item()\n",
    "            y_pred.extend(predicted.cpu().numpy())\n",
    "            y_true.extend(torch.max(labels, 1)[1].cpu().numpy())\n",
    "\n",
    "            loss = criterion(outputs, torch.max(labels, 1)[1])\n",
    "            total_loss += loss.item()\n",
    "    \n",
    "    accuracy = correct / total\n",
    "    avg_loss = total_loss / len(test_loader)\n",
    "    \n",
    "    return accuracy, avg_loss, y_true, y_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c38d9d16-e201-44c8-92df-886279dc2ea5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Função para treinamento do modelo\n",
    "def train(model, train_loader, test_loader, criterion, optimizer, \n",
    "          epochs=50, use_best_model=False, early_stop=False, es_range=1.0, show_trn_stats=True): \n",
    "    \n",
    "    score=9999\n",
    "    \n",
    "    if use_best_model:\n",
    "        best_score = 9999\n",
    "        best_epoch = 0\n",
    "        best_model_wts = copy.deepcopy(model.state_dict())\n",
    "    \n",
    "    model.train()\n",
    "    \n",
    "    for epoch in range(epochs):\n",
    "        running_loss = 0.0\n",
    "        \n",
    "        for data in train_loader:\n",
    "            inputs_tfidf, inputs_mes_dia_semana, labels = data\n",
    "            inputs_tfidf = inputs_tfidf.to(device) #####             #####\n",
    "            inputs_mes_dia_semana = inputs_mes_dia_semana.to(device) #####\n",
    "            labels = labels.to(device) #####                         #####\n",
    "            optimizer.zero_grad()\n",
    "            outputs = model(inputs_tfidf, inputs_mes_dia_semana)\n",
    "            loss = criterion(outputs, torch.max(labels, 1)[1]) \n",
    "            #loss = criterion(outputs, labels.float()) \n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            running_loss += loss.item()\n",
    "        \n",
    "        if use_best_model or early_stop or show_trn_stats:\n",
    "            accuracy, avg_loss, y_true, y_pred = evaluate_model(model, test_loader, criterion)\n",
    "            precision = precision_score(y_true, y_pred, average='weighted', zero_division=1)\n",
    "            recall = recall_score(y_true, y_pred, average='weighted', zero_division=1)\n",
    "            f1 = f1_score(y_true, y_pred, average='weighted', zero_division=1)\n",
    "            score_anterior = score\n",
    "            score = avg_loss\n",
    "            print(f\"Epoch {epoch+1}/{epochs}, Loss: {running_loss/len(train_loader):,.5f}\", \n",
    "                   f\"Acc: {accuracy:,.5f}\", \n",
    "                   f\"Prc: {precision:,.5f}\", \n",
    "                   f\"Rcl: {recall:,.5f}\", \n",
    "                    f\"F1: {f1:,.5f}\", \n",
    "                  f\"Test_loss: {avg_loss:,.5f}\")\n",
    "            #print(f\"Epoch {epoch+1}/{epochs}, Loss: {running_loss/len(train_loader):,.5f}, Score: {score:,.5f}\")\n",
    "        else:\n",
    "            print(f\"Epoch {epoch+1}/{epochs}, Loss: {running_loss/len(train_loader):,.5f}\")\n",
    "        \n",
    "        if use_best_model:\n",
    "            if score < best_score: \n",
    "                best_epoch = epoch+1\n",
    "                best_score = score\n",
    "                best_model_wts = copy.deepcopy(model.state_dict())\n",
    "                   \n",
    "        if use_best_model and early_stop and score > best_score*es_range: \n",
    "            print(f\"Interrompendo o treinamento...\")\n",
    "            break\n",
    "        \n",
    "        if early_stop and score >= score_anterior*es_range: # loss >\n",
    "            print(f\"Interrompendo o treinamento...\")\n",
    "            break\n",
    "            \n",
    "    # Limpeza do otimizador (liberacao da memoria gpu)\n",
    "    optimizer.zero_grad()\n",
    "    optimizer.state.clear()\n",
    "    # torch.cuda.empty_cache() if torch.cuda.is_available() else None\n",
    "    \n",
    "    if use_best_model and best_epoch!=epoch+1:\n",
    "        model.load_state_dict(best_model_wts)\n",
    "        print(f\"Carregando modelo da melhor epoca - {best_epoch}\")\n",
    "    print(f\"Fim.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8f637d8a-c164-4093-a07e-eb713bdbeab4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Definindo a função de perda e otimizadores ## weight_decay = regularizacao L2\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "#adam001 =   optim.AdamW(model.parameters(), weight_decay=0.1, lr=0.001)  ### padrao weight_decay=1e-2\n",
    "#adam0001 =   optim.AdamW(model.parameters(), weight_decay=0.1, lr=0.0001)"
   ]
  },
  {
   "cell_type": "raw",
   "id": "dd467531-8bf9-471c-81f4-cf3093ea5ba1",
   "metadata": {},
   "source": [
    "# Treinamento do modelo\n",
    "train(model, train_loader, test_loader, criterion,  adam01, epochs=11, use_best_model=True, early_stop=True) #*\n",
    "train(model, train_loader, test_loader, criterion,  adam005, epochs=12, use_best_model=True, early_stop=True) #*\n",
    "train(model, train_loader, test_loader, criterion,  adam0005, epochs=13, use_best_model=True, early_stop=True) #*\n",
    "train(model, train_loader, test_loader, criterion,  adam0001, epochs=14, use_best_model=True, early_stop=True) #*\n",
    "F1: 0.71027"
   ]
  },
  {
   "cell_type": "raw",
   "id": "570f9ee3-60d1-4c5b-b076-9453b666e90e",
   "metadata": {},
   "source": [
    "print (f'entrada: {input_tfidf_shape}+{input_mes_dia_semana_shape}={input_tfidf_shape+input_mes_dia_semana_shape}' )\n",
    "print('tamanho representacao binaria:', m.log(input_tfidf_shape+input_mes_dia_semana_shape)/m.log(2))\n",
    "#print (input_mes_dia_semana_shape)\n",
    "print ('saida:',output_shape)\n",
    "print('tamanho representacao binaria:',m.log(output_shape)/m.log(2))"
   ]
  },
  {
   "cell_type": "raw",
   "id": "565d38c0-ba05-425d-abc0-e399d0d2159c",
   "metadata": {},
   "source": [
    "%%time\n",
    "train(model, train_loader, test_loader, criterion, adam001, epochs=100, use_best_model=True, early_stop=True)\n",
    "train(model, train_loader, test_loader, criterion, adam0001, epochs=100, use_best_model=True, early_stop=True)\n",
    "# ref Epoch 100/100, Loss: 1.14011 Acc: 0.68548 Prc: 0.70413 Rcl: 0.68548 F1: 0.67362 Test_loss: 1.26200"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9f5c63af-7812-4f6b-a292-772499bf1496",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = torch.jit.load('modelo_tfidf_F1_0.92567_Loss_0.30878_20240524_214716.pt')\n",
    "model.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bec52886-8bb5-48bd-98d1-3f145b9fd935",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Avaliação do modelo nos dados de teste\n",
    "accuracy, avg_loss, y_true, y_pred = evaluate_model(model, test_loader, criterion)\n",
    "precision = precision_score(y_true, y_pred, average='weighted', zero_division=1)\n",
    "recall = recall_score(y_true, y_pred, average='weighted', zero_division=1)\n",
    "f1 = f1_score(y_true, y_pred, average='weighted', zero_division=1)\n",
    "print(f\"Acurácia: {accuracy:,.5f}\", f\"Precisão: {precision:,.5f}\", \n",
    "      f\"Recall: {recall:,.5f}\", f\"F1-score: {f1:,.5f}\", f\"Test_loss: {avg_loss:,.5f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8b4f041b-c747-4e8b-9493-80bb9d60af34",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculando a matriz de confusão\n",
    "conf_matrix = confusion_matrix(y_true, y_pred)\n",
    "# Criando a exibição da matriz de confusão\n",
    "disp = ConfusionMatrixDisplay(confusion_matrix=conf_matrix)\n",
    "plt.rcParams[\"figure.figsize\"] = (15,12)\n",
    "# Definindo o tamanho da figura\n",
    "plt.figure(figsize=(15, 12))\n",
    "# Obtendo a imagem da matriz de confusão com uma escala de cores personalizada\n",
    "im = disp.plot(cmap='viridis', xticks_rotation='vertical', values_format='d', colorbar=False)\n",
    "\n",
    "################### Ajustando as cores para a escala logarítmica #################################\n",
    "im = plt.imshow(conf_matrix, interpolation='nearest', cmap='viridis', norm=LogNorm())\n",
    "# Adicionando a barra de cores\n",
    "#plt.colorbar(im)\n",
    "# Ajustando o tamanho da fonte manualmente\n",
    "for text in im.axes.texts:\n",
    "    text.set_fontsize(6)\n",
    "# Exibindo a figura\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ec2a6b43-a3b8-4fe0-b741-bdab8df1ce76",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(label_encoder.inverse_transform([2]))\n",
    "print(label_encoder.inverse_transform([7]))\n",
    "print(label_encoder.inverse_transform([24]))\n",
    "print(label_encoder.inverse_transform([25]))\n",
    "print(label_encoder.inverse_transform([30]))\n",
    "print(label_encoder.inverse_transform([31]))\n",
    "print(label_encoder.inverse_transform([32]))\n",
    "print(label_encoder.inverse_transform([38]))\n",
    "print(label_encoder.inverse_transform([40]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e69e2b1a-1bfc-47fb-aa80-c928d628cdb7",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
